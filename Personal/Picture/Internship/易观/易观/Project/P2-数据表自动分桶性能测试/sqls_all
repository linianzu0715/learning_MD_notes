--案例6：6个hash用户桶
/*@平台管理员#retention-1*/ select "profile_$city" as attrValue,cast(state[1] as integer)*1 as totalUserCount , cast(state[2] as integer)*1 as dayUserCount0, cast(state[3] as integer)*1 as dayUserCount1, cast(state[4] as integer)*1 as dayUserCount2, cast(state[5] as integer)*1 as dayUserCount3, cast(state[6] as integer)*1 as dayUserCount4, cast(state[7] as integer)*1 as dayUserCount5, cast(state[8] as integer)*1 as dayUserCount6, cast(state[9] as integer)*1 as dayUserCount7, cast(state[10] as integer)*1 as dayUserCount8, cast(state[11] as integer)*1 as dayUserCount9, cast(state[12] as integer)*1 as dayUserCount10, cast(state[13] as integer)*1 as dayUserCount11, cast(state[14] as integer)*1 as dayUserCount12, cast(state[15] as integer)*1 as dayUserCount13, cast(state[16] as integer)*1 as dayUserCount14, cast(state[17] as integer)*1 as dayUserCount15, cast(state[18] as integer)*1 as dayUserCount16, cast(state[19] as integer)*1 as dayUserCount17, cast(state[20] as integer)*1 as dayUserCount18, cast(state[21] as integer)*1 as dayUserCount19, cast(state[22] as integer)*1 as dayUserCount20, cast(state[23] as integer)*1 as dayUserCount21, cast(state[24] as integer)*1 as dayUserCount22, cast(state[25] as integer)*1 as dayUserCount23, cast(state[26] as integer)*1 as dayUserCount24, cast(state[27] as integer)*1 as dayUserCount25, cast(state[28] as integer)*1 as dayUserCount26, cast(state[29] as integer)*1 as dayUserCount27, cast(state[30] as integer)*1 as dayUserCount28, cast(state[31] as integer)*1 as dayUserCount29, cast(state[32] as integer)*1 as dayUserCount30  from ( select "profile_$city",retention_sum_grouping(distinct_id_state,60,30,-1) as state  from ( select event.distinct_id,cast(  COALESCE(profile."$city",'(无值)')  as varchar) as "profile_$city" , retention_count_grouping(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast( event.xwhen/1000 - 1583164800 as integer),cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,-1,-1,-1,-1) as distinct_id_state  from hive.db_514fec3bdc58ccad.event event  left join hive.db_514fec3bdc58ccad.profile_vd profile  on event.distinct_id = profile.distinct_id  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id ,   COALESCE(profile."$city",'(无值)') )  where distinct_id_state is not null group by 1 )  order by   totalUserCount desc  limit 50

--案例6：动态分桶，预拆分成4个range用户桶
/*@平台管理员#retention-1*/ select "profile_$city" as attrValue,cast(state[1] as integer)*1 as totalUserCount , cast(state[2] as integer)*1 as dayUserCount0, cast(state[3] as integer)*1 as dayUserCount1, cast(state[4] as integer)*1 as dayUserCount2, cast(state[5] as integer)*1 as dayUserCount3, cast(state[6] as integer)*1 as dayUserCount4, cast(state[7] as integer)*1 as dayUserCount5, cast(state[8] as integer)*1 as dayUserCount6, cast(state[9] as integer)*1 as dayUserCount7, cast(state[10] as integer)*1 as dayUserCount8, cast(state[11] as integer)*1 as dayUserCount9, cast(state[12] as integer)*1 as dayUserCount10, cast(state[13] as integer)*1 as dayUserCount11, cast(state[14] as integer)*1 as dayUserCount12, cast(state[15] as integer)*1 as dayUserCount13, cast(state[16] as integer)*1 as dayUserCount14, cast(state[17] as integer)*1 as dayUserCount15, cast(state[18] as integer)*1 as dayUserCount16, cast(state[19] as integer)*1 as dayUserCount17, cast(state[20] as integer)*1 as dayUserCount18, cast(state[21] as integer)*1 as dayUserCount19, cast(state[22] as integer)*1 as dayUserCount20, cast(state[23] as integer)*1 as dayUserCount21, cast(state[24] as integer)*1 as dayUserCount22, cast(state[25] as integer)*1 as dayUserCount23, cast(state[26] as integer)*1 as dayUserCount24, cast(state[27] as integer)*1 as dayUserCount25, cast(state[28] as integer)*1 as dayUserCount26, cast(state[29] as integer)*1 as dayUserCount27, cast(state[30] as integer)*1 as dayUserCount28, cast(state[31] as integer)*1 as dayUserCount29, cast(state[32] as integer)*1 as dayUserCount30  from ( select "profile_$city",retention_sum_grouping(distinct_id_state,60,30,-1) as state  from ( select event.distinct_id,cast(  COALESCE(profile."$city",'(无值)')  as varchar) as "profile_$city" , retention_count_grouping(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast( event.xwhen/1000 - 1583164800 as integer),cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,-1,-1,-1,-1) as distinct_id_state  from hive.db_514fec3bdc58ccad.event_dynamic event  left join hive.db_514fec3bdc58ccad.profile_vd profile  on event.distinct_id = profile.distinct_id  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id ,   COALESCE(profile."$city",'(无值)') )  where distinct_id_state is not null group by 1 )  order by   totalUserCount desc  limit 50

--案例7：6个hash用户桶
/*@平台管理员#retention-1*/ select state[1] AS attrValue,cast(state[2] as integer) *1 as totalUserCount , cast(state[3] as integer) *1 as dayUserCount0, cast(state[4] as integer) *1 as dayUserCount1, cast(state[5] as integer) *1 as dayUserCount2, cast(state[6] as integer) *1 as dayUserCount3, cast(state[7] as integer) *1 as dayUserCount4, cast(state[8] as integer) *1 as dayUserCount5, cast(state[9] as integer) *1 as dayUserCount6, cast(state[10] as integer) *1 as dayUserCount7, cast(state[11] as integer) *1 as dayUserCount8, cast(state[12] as integer) *1 as dayUserCount9, cast(state[13] as integer) *1 as dayUserCount10, cast(state[14] as integer) *1 as dayUserCount11, cast(state[15] as integer) *1 as dayUserCount12, cast(state[16] as integer) *1 as dayUserCount13, cast(state[17] as integer) *1 as dayUserCount14, cast(state[18] as integer) *1 as dayUserCount15, cast(state[19] as integer) *1 as dayUserCount16, cast(state[20] as integer) *1 as dayUserCount17, cast(state[21] as integer) *1 as dayUserCount18, cast(state[22] as integer) *1 as dayUserCount19, cast(state[23] as integer) *1 as dayUserCount20, cast(state[24] as integer) *1 as dayUserCount21, cast(state[25] as integer) *1 as dayUserCount22, cast(state[26] as integer) *1 as dayUserCount23, cast(state[27] as integer) *1 as dayUserCount24, cast(state[28] as integer) *1 as dayUserCount25, cast(state[29] as integer) *1 as dayUserCount26, cast(state[30] as integer) *1 as dayUserCount27, cast(state[31] as integer) *1 as dayUserCount28, cast(state[32] as integer) *1 as dayUserCount29, cast(state[33] as integer) *1 as dayUserCount30  from ( select state  from ( select retention_sum_simple(state, 60,30,-1) as distinct_id_state  from ( select event.distinct_id, retention_count_simple(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,-1,-1) as state  from hive.db_514fec3bdc58ccad.event event  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id ))   cross join unnest(distinct_id_state) as t (state)  ) 

--案例7：动态分桶，预拆分成4个range用户桶
/*@平台管理员#retention-1*/ select state[1] AS attrValue,cast(state[2] as integer) *1 as totalUserCount , cast(state[3] as integer) *1 as dayUserCount0, cast(state[4] as integer) *1 as dayUserCount1, cast(state[5] as integer) *1 as dayUserCount2, cast(state[6] as integer) *1 as dayUserCount3, cast(state[7] as integer) *1 as dayUserCount4, cast(state[8] as integer) *1 as dayUserCount5, cast(state[9] as integer) *1 as dayUserCount6, cast(state[10] as integer) *1 as dayUserCount7, cast(state[11] as integer) *1 as dayUserCount8, cast(state[12] as integer) *1 as dayUserCount9, cast(state[13] as integer) *1 as dayUserCount10, cast(state[14] as integer) *1 as dayUserCount11, cast(state[15] as integer) *1 as dayUserCount12, cast(state[16] as integer) *1 as dayUserCount13, cast(state[17] as integer) *1 as dayUserCount14, cast(state[18] as integer) *1 as dayUserCount15, cast(state[19] as integer) *1 as dayUserCount16, cast(state[20] as integer) *1 as dayUserCount17, cast(state[21] as integer) *1 as dayUserCount18, cast(state[22] as integer) *1 as dayUserCount19, cast(state[23] as integer) *1 as dayUserCount20, cast(state[24] as integer) *1 as dayUserCount21, cast(state[25] as integer) *1 as dayUserCount22, cast(state[26] as integer) *1 as dayUserCount23, cast(state[27] as integer) *1 as dayUserCount24, cast(state[28] as integer) *1 as dayUserCount25, cast(state[29] as integer) *1 as dayUserCount26, cast(state[30] as integer) *1 as dayUserCount27, cast(state[31] as integer) *1 as dayUserCount28, cast(state[32] as integer) *1 as dayUserCount29, cast(state[33] as integer) *1 as dayUserCount30  from ( select state  from ( select retention_sum_simple(state, 60,30,-1) as distinct_id_state  from ( select event.distinct_id, retention_count_simple(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,-1,-1) as state  from hive.db_514fec3bdc58ccad.event_dynamic event  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id ))   cross join unnest(distinct_id_state) as t (state)  ) 

--案例8：6个hash用户桶
/*@平台管理员#retention-1*/ select "$$attr","$$attr" as attrValue ,cast(state[1] as integer)*1 as totalUserCount , cast(state[2] as integer)*1 as dayUserCount0, cast(state[3] as integer)*1 as dayUserCount1, cast(state[4] as integer)*1 as dayUserCount2, cast(state[5] as integer)*1 as dayUserCount3, cast(state[6] as integer)*1 as dayUserCount4, cast(state[7] as integer)*1 as dayUserCount5, cast(state[8] as integer)*1 as dayUserCount6, cast(state[9] as integer)*1 as dayUserCount7, cast(state[10] as integer)*1 as dayUserCount8, cast(state[11] as integer)*1 as dayUserCount9, cast(state[12] as integer)*1 as dayUserCount10, cast(state[13] as integer)*1 as dayUserCount11, cast(state[14] as integer)*1 as dayUserCount12, cast(state[15] as integer)*1 as dayUserCount13, cast(state[16] as integer)*1 as dayUserCount14, cast(state[17] as integer)*1 as dayUserCount15, cast(state[18] as integer)*1 as dayUserCount16, cast(state[19] as integer)*1 as dayUserCount17, cast(state[20] as integer)*1 as dayUserCount18, cast(state[21] as integer)*1 as dayUserCount19, cast(state[22] as integer)*1 as dayUserCount20, cast(state[23] as integer)*1 as dayUserCount21, cast(state[24] as integer)*1 as dayUserCount22, cast(state[25] as integer)*1 as dayUserCount23, cast(state[26] as integer)*1 as dayUserCount24, cast(state[27] as integer)*1 as dayUserCount25, cast(state[28] as integer)*1 as dayUserCount26, cast(state[29] as integer)*1 as dayUserCount27, cast(state[30] as integer)*1 as dayUserCount28, cast(state[31] as integer)*1 as dayUserCount29, cast(state[32] as integer)*1 as dayUserCount30  from ( select distinct_id_state[1] as "$$attr",retention_sum_grouping(distinct_id_state,60,30,-1) as state  from ( select event.distinct_id, retention_count_grouping(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast( event.xwhen/1000 - 1583164800 as integer),cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,0,eattr( case when event."$producttype" is null then '(无值)' when cardinality(event."$producttype")=0 then '' else array_join(event."$producttype",  ',') end ),-1,-1) as distinct_id_state  from hive.db_514fec3bdc58ccad.event event  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id )  where distinct_id_state is not null group by 1 )  order by  1  limit 50

--案例8：动态分桶，预拆分成4个range用户桶
/*@平台管理员#retention-1*/ select "$$attr","$$attr" as attrValue ,cast(state[1] as integer)*1 as totalUserCount , cast(state[2] as integer)*1 as dayUserCount0, cast(state[3] as integer)*1 as dayUserCount1, cast(state[4] as integer)*1 as dayUserCount2, cast(state[5] as integer)*1 as dayUserCount3, cast(state[6] as integer)*1 as dayUserCount4, cast(state[7] as integer)*1 as dayUserCount5, cast(state[8] as integer)*1 as dayUserCount6, cast(state[9] as integer)*1 as dayUserCount7, cast(state[10] as integer)*1 as dayUserCount8, cast(state[11] as integer)*1 as dayUserCount9, cast(state[12] as integer)*1 as dayUserCount10, cast(state[13] as integer)*1 as dayUserCount11, cast(state[14] as integer)*1 as dayUserCount12, cast(state[15] as integer)*1 as dayUserCount13, cast(state[16] as integer)*1 as dayUserCount14, cast(state[17] as integer)*1 as dayUserCount15, cast(state[18] as integer)*1 as dayUserCount16, cast(state[19] as integer)*1 as dayUserCount17, cast(state[20] as integer)*1 as dayUserCount18, cast(state[21] as integer)*1 as dayUserCount19, cast(state[22] as integer)*1 as dayUserCount20, cast(state[23] as integer)*1 as dayUserCount21, cast(state[24] as integer)*1 as dayUserCount22, cast(state[25] as integer)*1 as dayUserCount23, cast(state[26] as integer)*1 as dayUserCount24, cast(state[27] as integer)*1 as dayUserCount25, cast(state[28] as integer)*1 as dayUserCount26, cast(state[29] as integer)*1 as dayUserCount27, cast(state[30] as integer)*1 as dayUserCount28, cast(state[31] as integer)*1 as dayUserCount29, cast(state[32] as integer)*1 as dayUserCount30  from ( select distinct_id_state[1] as "$$attr",retention_sum_grouping(distinct_id_state,60,30,-1) as state  from ( select event.distinct_id, retention_count_grouping(array[ case when ( (event.xwhat_id=7)  and event."$channel" in ('今日头条','百度')) and  event.ds between 20200303 and 20200501 then 0 else -1 end ,  case when ( (event.xwhat_id=1)  and event."$app_version" in ('V1.0')) then 1 else -1 end ,  -1 ],cast( event.xwhen/1000 - 1583164800 as integer),cast(date_diff('day', from_iso8601_timestamp('2020-03-03'), parse_datetime(CAST(event.ds AS varchar),'YYYYMMdd')) as integer),60,30,0,eattr( case when event."$producttype" is null then '(无值)' when cardinality(event."$producttype")=0 then '' else array_join(event."$producttype",  ',') end ),-1,-1) as distinct_id_state  from hive.db_514fec3bdc58ccad.event_dynamic event  where (event.xwhat_id=7 or event.xwhat_id=1) and ( event.ds between 20200303 and 20200531) group by  event.distinct_id )  where distinct_id_state is not null group by 1 )  order by  1  limit 50

--案例11：6个hash用户桶
/*@平台管理员#funnel-1*/ select attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex , coalesce (cast(attrValue as varchar),'-1') as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state ,attrValue from  (  select  event.distinct_id, cast(  COALESCE(profile."$city",'(无值)') as varchar) as attrValue , funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,-1,-1) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event left join  ( select "$city",distinct_id from hive.db_514fec3bdc58ccad.profile_vd) profile on event.distinct_id = profile.distinct_id  where   1=1   group by  event.distinct_id ,  COALESCE(profile."$city",'(无值)')  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1],rollup(attrValue) ) group by 1 order by step1[1] desc limit 50

--案例11：动态分桶，预拆分成4个range用户桶
/*@平台管理员#funnel-1*/ select attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex , coalesce (cast(attrValue as varchar),'-1') as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state ,attrValue from  (  select  event.distinct_id, cast(  COALESCE(profile."$city",'(无值)') as varchar) as attrValue , funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,-1,-1) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event_dynamic as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event left join  ( select "$city",distinct_id from hive.db_514fec3bdc58ccad.profile_vd) profile on event.distinct_id = profile.distinct_id  where   1=1   group by  event.distinct_id ,  COALESCE(profile."$city",'(无值)')  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1],rollup(attrValue) ) group by 1 order by step1[1] desc limit 50

--案例12：6个hash用户桶
/*@平台管理员#funnel-1*/ select  '-1' as attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex ,  '-1' as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state  from  (  select  event.distinct_id,  funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,-1,-1) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event where   1=1   group by  event.distinct_id  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1] )  limit 50

--案例12：动态分桶，预拆分成4个range用户桶
/*@平台管理员#funnel-1*/ select  '-1' as attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex ,  '-1' as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state  from  (  select  event.distinct_id,  funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,-1,-1) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event_dynamic as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event where   1=1   group by  event.distinct_id  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1] )  limit 50

--案例13：6个hash用户桶
/*@平台管理员#funnel-1*/ select attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex , coalesce (attrValue ,-1) as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state ,state[2] as attrValue from  (  select  event.distinct_id,  funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,0,eattr(  COALESCE(event."$os",'(无值)') )) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event where   1=1   group by  event.distinct_id  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1],rollup(attrValue) ) group by 1 order by step1[1] desc limit 50

--案例13：动态分桶，预拆分成4个range用户桶
/*@平台管理员#funnel-1*/ select attrValue, array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step1) as step1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step2) as step2,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),step3) as step3,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median1) as median1,array_fill( date_diff('day',parse_datetime('20200303','YYYYMMdd'),parse_datetime('20200531','YYYYMMdd'))+2,cast(coalesce(dayIndex+1,0) as bigint),median2) as median2 from ( select  state[1] as dayIndex , coalesce (attrValue ,-1) as attrValue, count_if(state[3]>=1)*1 as step1, count_if(state[3]>=2)*1 as step2, count_if(state[3]>=3)*1 as step3, approx_percentile(case when state[3]>=2 then state[5] end,0.5) as median1, approx_percentile(case when state[3]>=3 then state[6] end,0.5) as median2 from  (  select  distinct_id, state ,state[2] as attrValue from  (  select  event.distinct_id,  funnel_count_large(  array[  case when event.xwhat_id=7 and  event.ds between 20200303 and 20200531 and (event."$channel" in ('百度','微信'))  then 0 else -1 end , case when event.xwhat_id=1 and (event."$app_version" in ('V1.0'))  then 1 else -1 end , case when event.xwhat_id=20 and (event."$os" in ('Unknown','Cloud','Android','Ubuntu'))  then 2 else -1 end  ] ,-1,array[cast(1 as double)],-1,array[-1], CAST(xwhen - 1583164800000 as bigint),86400000,90,0,eattr(  COALESCE(event."$os",'(无值)') )) as distinct_id_state  from  ( select ds,distinct_id,xwhen,xwhat,xwhat_id,"$channel","$app_version","$os" from hive.db_514fec3bdc58ccad.event_dynamic as event where 1=1    and  event.ds between 20200303 and 20200601 and( (xwhat_id=7 and event."$channel" in ('百度','微信')) or (xwhat_id=1 and event."$app_version" in ('V1.0')) or (xwhat_id=20 and event."$os" in ('Unknown','Cloud','Android','Ubuntu')))) event where   1=1   group by  event.distinct_id  )  cross join unnest(distinct_id_state) as t (state)  )  group by state[1],rollup(attrValue) ) group by 1 order by step1[1] desc limit 50

--案例14：6个hash用户桶
/*@平台管理员#userPath-1*/ select state_topn[1] as KEY,  cast(state_topn[2] as bigint) as VALUE  from (    select path_count_topN(key,value) as path_state_topn from (  SELECT state[1] AS key,	         sum(cast(state[2] AS bigint)) AS value	 FROM	    ( SELECT event.distinct_id,	 path_count( event.xwhat_id,cast(event.xwhen/1000 as integer), 		   		 eattr('')	 , 	   		 CASE WHEN  event.xwhat_id=7   	THEN  1  ELSE 0 end   ,				1800 ) AS path_state		   FROM hive.db_514fec3bdc58ccad.event event		    LEFT JOIN hive.db_514fec3bdc58ccad.profile_vd profile	ON event.distinct_id = profile.distinct_id              WHERE  event.ds between 20200303 and 20200531			  AND (    profile."xwho" is not null 		  )  				   				 				 AND ( 			  event.xwhat_id  IN (  27,1,9,8,13,15,14,20,21,19,25,31,34,35,37,40,41,43,46,47,52,53,51,58,57,60,63,64,67,68,71,72,74,78,77,81,82,85,87,86,92,91,95,100,99,104,103,108,107,112,111,115,119,122,123,121,127,128,131,132,134,138,137,141,142,145,149,150,154,153,158,157,161,165,166,169,170,173,174,178,177,181,182,186,185,189,191,190,196,195,199,200,204,203,207,208,211,213,217,220,219,223,226,225,230,229,231,235,237,238,241,242,246,245,249,250,253,254,258,261,262,266,265,270,269,273,275,277,281,283,285,289,291,293,294,297,299,303,305,307,309,313	)	 OR	 (  	 event.xwhat_id = 7   )						 			            			 ) 	   GROUP BY  event.distinct_id )		   CROSS JOIN unnest(path_state) AS t (state)		   GROUP BY  state[1]	 ) )CROSS JOIN unnest (path_state_topn) AS t (state_topn)

--案例14:动态分桶，预拆分成4个range用户桶
/*@平台管理员#userPath-1*/ select state_topn[1] as KEY,  cast(state_topn[2] as bigint) as VALUE  from (    select path_count_topN(key,value) as path_state_topn from (  SELECT state[1] AS key,	         sum(cast(state[2] AS bigint)) AS value	 FROM	    ( SELECT event.distinct_id,	 path_count( event.xwhat_id,cast(event.xwhen/1000 as integer), 		   		 eattr('')	 , 	   		 CASE WHEN  event.xwhat_id=7   	THEN  1  ELSE 0 end   ,				1800 ) AS path_state		   FROM hive.db_514fec3bdc58ccad.event_dynamic event		    LEFT JOIN hive.db_514fec3bdc58ccad.profile_vd profile	ON event.distinct_id = profile.distinct_id              WHERE  event.ds between 20200303 and 20200531			  AND (    profile."xwho" is not null 		  )  				   				 				 AND ( 			  event.xwhat_id  IN (  27,1,9,8,13,15,14,20,21,19,25,31,34,35,37,40,41,43,46,47,52,53,51,58,57,60,63,64,67,68,71,72,74,78,77,81,82,85,87,86,92,91,95,100,99,104,103,108,107,112,111,115,119,122,123,121,127,128,131,132,134,138,137,141,142,145,149,150,154,153,158,157,161,165,166,169,170,173,174,178,177,181,182,186,185,189,191,190,196,195,199,200,204,203,207,208,211,213,217,220,219,223,226,225,230,229,231,235,237,238,241,242,246,245,249,250,253,254,258,261,262,266,265,270,269,273,275,277,281,283,285,289,291,293,294,297,299,303,305,307,309,313	)	 OR	 (  	 event.xwhat_id = 7   )						 			            			 ) 	   GROUP BY  event.distinct_id )		   CROSS JOIN unnest(path_state) AS t (state)		   GROUP BY  state[1]	 ) )CROSS JOIN unnest (path_state_topn) AS t (state_topn)
